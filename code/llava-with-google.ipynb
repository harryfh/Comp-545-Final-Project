{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7917611,"sourceType":"datasetVersion","datasetId":4652364}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade google-cloud-aiplatform","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"import base64\nimport os\nimport cv2\nimport json\nimport random\n\nrandom.seed(10)\ndef load_dataset(datapath):\n    with open(datapath, 'r') as f:  # Open file with 'r' for read mode\n        data = json.load(f)\n    return data\n                \ndef concate_images(image_1, image_2):\n    img1 = cv2.imread(image_1) \n    img2 = cv2.imread(image_2)\n    if img1.shape[0] != img2.shape[0]:  # Check if heights are the same\n        target_height = max(img1.shape[0], img2.shape[0]) \n        img1 = cv2.resize(img1, (img1.shape[1], target_height))\n        img2 = cv2.resize(img2, (img2.shape[1], target_height))\n\n    im_h = cv2.hconcat([img1, img2])\n    cv2.imwrite('/kaggle/working/temp.jpg', im_h) \n    return '/kaggle/working/temp.jpg'\n    \ndef encode_image(image):\n    with open(image, \"rb\") as image_file:\n        encoded_string = base64.b64encode(image_file.read())\n    return encoded_string\n\ndef image_caption_generator(concatenated=False):\n    dataset = load_dataset('/kaggle/input/imagecode-simple/valid_simple.json')\n    imagepath = '/kaggle/input/imagecode-simple/image-sets/image-sets'\n    for data in dataset:\n        directory, pos_idx, neg_idx, caption = data.values()\n        file_list = sorted([file for file in os.listdir(f'{imagepath}/{directory}')], key=lambda x: int(x.split('.')[0][3:]))\n        pos_img = f'{imagepath}/{directory}/{file_list[pos_idx]}'\n        neg_img = f'{imagepath}/{directory}/{file_list[neg_idx]}'\n        if concatenated:\n            if random.randint(0,1) == 1:\n                concatenated = concate_images(pos_img, neg_img)\n                label = \"Left\"\n            else:\n                concatenated = concate_images(neg_img, pos_img)\n                label = \"Right\"\n            if concatenated is None:\n                continue \n                \n            yield concatenated, caption, label, directory, pos_idx, neg_idx\n        else:\n            if random.randint(0,1) == 1:\n                img1 = pos_img\n                img2 = neg_img\n                label = \"Image 1\"\n            else:\n                img1 = neg_img\n                img2 = pos_img\n                label = \"Image 2\"\n            yield img1, img2, caption, label\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T20:14:01.114525Z","iopub.execute_input":"2024-04-13T20:14:01.115689Z","iopub.status.idle":"2024-04-13T20:14:01.134628Z","shell.execute_reply.started":"2024-04-13T20:14:01.115638Z","shell.execute_reply":"2024-04-13T20:14:01.132971Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Gemini","metadata":{}},{"cell_type":"code","source":"import base64\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel, Part, FinishReason, Image\nimport vertexai.preview.generative_models as generative_models\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\n\ngeneration_config = {\n    \"max_output_tokens\": 2048,\n    \"temperature\": 0.1,\n    \"top_p\": 1,\n    \"top_k\": 32,\n}\n\nsafety_settings = {\n    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n}\n\ndef generate(img1, img2, caption):\n    vertexai.init(project=\"imagecodechallenge\", location=\"us-central1\")\n    model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n    img1 = Image.load_from_file(img1)\n    img2 = Image.load_from_file(img2)\n    \n    responses = model.generate_content(\n      [\"Image 1:\", img1, \"Image 2:\", img2,\n       f\"Please tell me which of these images is described by the caption: {caption}. End your answer with: The answer is Image [1 or 2]\"],\n      generation_config=generation_config,\n      safety_settings=safety_settings,\n      stream=False,\n    )\n    try:\n        return responses.text\n    except (ValueError, AttributeError) as e: # Response Failed \n        return None\n\nresults = []\n\nfor img1, img2, caption, label in image_caption_generator(concatenated=False):\n    response = generate(img1, img2, caption)\n    if response:\n        results.append({\"img1\": img1, \"img2\" : img2, \"caption\": caption, \"label\":label, \"answer\": response[-9:], \"response\" : response})\n    else:\n        print(\"Call failed\")\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/ZeroShotCoTGeminiResults_0-415Valid.json', 'w') as outfile:\n    json.dump(results, outfile, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:11:22.313777Z","iopub.execute_input":"2024-04-13T19:11:22.314313Z","iopub.status.idle":"2024-04-13T19:11:22.333782Z","shell.execute_reply.started":"2024-04-13T19:11:22.314274Z","shell.execute_reply":"2024-04-13T19:11:22.332089Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import re\nwith open('/kaggle/working/ZeroShotCoTGeminiResults_0-415Valid.json', 'r') as file:\n    data = json.load(file)\ntotal = 0\ncorrect = 0\nfor a in data:\n    if a['label'] in a['answer']:\n        correct += 1\n    else:\n        m = re.search(r\"The answer is (Image [12])\", a['response'])\n        correct += 1 if m and a['label'] in m.group(0) else 0\n        \n    total += 1\n    \n\nprint(correct/total)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T19:29:29.674720Z","iopub.execute_input":"2024-04-13T19:29:29.675135Z","iopub.status.idle":"2024-04-13T19:29:29.688624Z","shell.execute_reply.started":"2024-04-13T19:29:29.675102Z","shell.execute_reply":"2024-04-13T19:29:29.687297Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"0.6642335766423357\n","output_type":"stream"}]}]}